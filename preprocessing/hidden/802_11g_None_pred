digraph {
	graph [size="48.75,48.75"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140168439777808 [label="
 (12, 4)" fillcolor=darkolivegreen1]
	140168439727728 [label=LogSoftmaxBackward0]
	140168439729600 -> 140168439727728
	140168439729600 [label=AddmmBackward0]
	140168439356944 -> 140168439729600
	140168439293296 [label="classifier.bias
 (4)" fillcolor=lightblue]
	140168439293296 -> 140168439356944
	140168439356944 [label=AccumulateGrad]
	140168439734400 -> 140168439729600
	140168439734400 [label=ReluBackward0]
	140168439729888 -> 140168439734400
	140168439729888 [label=AddmmBackward0]
	140168439357184 -> 140168439729888
	140168439293104 [label="pre_classifier.bias
 (128)" fillcolor=lightblue]
	140168439293104 -> 140168439357184
	140168439357184 [label=AccumulateGrad]
	140168439734640 -> 140168439729888
	140168439734640 [label=ViewBackward0]
	140168439734688 -> 140168439734640
	140168439734688 [label=NativeLayerNormBackward0]
	140168439734880 -> 140168439734688
	140168439734880 [label=AddBackward0]
	140168439734976 -> 140168439734880
	140168439734976 [label=NativeLayerNormBackward0]
	140168439735120 -> 140168439734976
	140168439735120 [label=AddBackward0]
	140168439735216 -> 140168439735120
	140168439735216 [label=NativeLayerNormBackward0]
	140168439735360 -> 140168439735216
	140168439735360 [label=AddBackward0]
	140168439735456 -> 140168439735360
	140168439735456 [label=NativeLayerNormBackward0]
	140168439735600 -> 140168439735456
	140168439735600 [label=AddBackward0]
	140168439735696 -> 140168439735600
	140168439735696 [label=NativeLayerNormBackward0]
	140168439358816 -> 140168439735696
	140168439288592 [label="norm.weight
 (128)" fillcolor=lightblue]
	140168439288592 -> 140168439358816
	140168439358816 [label=AccumulateGrad]
	140168439358768 -> 140168439735696
	140168439288688 [label="norm.bias
 (128)" fillcolor=lightblue]
	140168439288688 -> 140168439358768
	140168439358768 [label=AccumulateGrad]
	140168439735648 -> 140168439735600
	140168439735648 [label=TransposeBackward0]
	140168439735744 -> 140168439735648
	140168439735744 [label=ViewBackward0]
	140168439735936 -> 140168439735744
	140168439735936 [label=AddmmBackward0]
	140168439359104 -> 140168439735936
	140168439290896 [label="transformer_encoder.layers.0.self_attn.out_proj.bias
 (128)" fillcolor=lightblue]
	140168439290896 -> 140168439359104
	140168439359104 [label=AccumulateGrad]
	140168439736032 -> 140168439735936
	140168439736032 [label=ViewBackward0]
	140168439736080 -> 140168439736032
	140168439736080 [label=CloneBackward0]
	140168439736272 -> 140168439736080
	140168439736272 [label=PermuteBackward0]
	140168439736368 -> 140168439736272
	140168439736368 [label=ScaledDotProductFlashAttentionForCpuBackward0]
	140168439736464 -> 140168439736368
	140168439736464 [label=ViewBackward0]
	140168439736656 -> 140168439736464
	140168439736656 [label=TransposeBackward0]
	140168439736752 -> 140168439736656
	140168439736752 [label=ViewBackward0]
	140168439736848 -> 140168439736752
	140168439736848 [label=SelectBackward0]
	140168439736944 -> 140168439736848
	140168439736944 [label=CloneBackward0]
	140168439737040 -> 140168439736944
	140168439737040 [label=SqueezeBackward1]
	140168439737136 -> 140168439737040
	140168439737136 [label=TransposeBackward0]
	140168439737232 -> 140168439737136
	140168439737232 [label=UnsqueezeBackward0]
	140168439737328 -> 140168439737232
	140168439737328 [label=ViewBackward0]
	140168439737424 -> 140168439737328
	140168439737424 [label=AddBackward0]
	140168439737520 -> 140168439737424
	140168439737520 [label=UnsafeViewBackward0]
	140168439737616 -> 140168439737520
	140168439737616 [label=MmBackward0]
	140168439737712 -> 140168439737616
	140168439737712 [label=UnsafeViewBackward0]
	140168439737856 -> 140168439737712
	140168439737856 [label=CloneBackward0]
	140168439737952 -> 140168439737856
	140168439737952 [label=TransposeBackward0]
	140168439735696 -> 140168439737952
	140168439737664 -> 140168439737616
	140168439737664 [label=TBackward0]
	140168439361216 -> 140168439737664
	140168439288880 [label="transformer_encoder.layers.0.self_attn.in_proj_weight
 (384, 128)" fillcolor=lightblue]
	140168439288880 -> 140168439361216
	140168439361216 [label=AccumulateGrad]
	140168439360592 -> 140168439737424
	140168439290512 [label="transformer_encoder.layers.0.self_attn.in_proj_bias
 (384)" fillcolor=lightblue]
	140168439290512 -> 140168439360592
	140168439360592 [label=AccumulateGrad]
	140168439736416 -> 140168439736368
	140168439736416 [label=ViewBackward0]
	140168439736800 -> 140168439736416
	140168439736800 [label=TransposeBackward0]
	140168439736992 -> 140168439736800
	140168439736992 [label=ViewBackward0]
	140168439737184 -> 140168439736992
	140168439737184 [label=SelectBackward0]
	140168439736944 -> 140168439737184
	140168439736176 -> 140168439736368
	140168439736176 [label=ViewBackward0]
	140168439737088 -> 140168439736176
	140168439737088 [label=TransposeBackward0]
	140168439737280 -> 140168439737088
	140168439737280 [label=ViewBackward0]
	140168439737472 -> 140168439737280
	140168439737472 [label=SelectBackward0]
	140168439736944 -> 140168439737472
	140168439735984 -> 140168439735936
	140168439735984 [label=TBackward0]
	140168439359440 -> 140168439735984
	140168439290608 [label="transformer_encoder.layers.0.self_attn.out_proj.weight
 (128, 128)" fillcolor=lightblue]
	140168439290608 -> 140168439359440
	140168439359440 [label=AccumulateGrad]
	140168439358432 -> 140168439735456
	140168439291376 [label="transformer_encoder.layers.0.norm1.weight
 (128)" fillcolor=lightblue]
	140168439291376 -> 140168439358432
	140168439358432 [label=AccumulateGrad]
	140168439358384 -> 140168439735456
	140168439291472 [label="transformer_encoder.layers.0.norm1.bias
 (128)" fillcolor=lightblue]
	140168439291472 -> 140168439358384
	140168439358384 [label=AccumulateGrad]
	140168439735408 -> 140168439735360
	140168439735408 [label=ViewBackward0]
	140168439735792 -> 140168439735408
	140168439735792 [label=AddmmBackward0]
	140168439359152 -> 140168439735792
	140168439291280 [label="transformer_encoder.layers.0.linear2.bias
 (128)" fillcolor=lightblue]
	140168439291280 -> 140168439359152
	140168439359152 [label=AccumulateGrad]
	140168439735840 -> 140168439735792
	140168439735840 [label=ViewBackward0]
	140168439736320 -> 140168439735840
	140168439736320 [label=ReluBackward0]
	140168439736896 -> 140168439736320
	140168439736896 [label=ViewBackward0]
	140168439736608 -> 140168439736896
	140168439736608 [label=AddmmBackward0]
	140168439360736 -> 140168439736608
	140168439291088 [label="transformer_encoder.layers.0.linear1.bias
 (2048)" fillcolor=lightblue]
	140168439291088 -> 140168439360736
	140168439360736 [label=AccumulateGrad]
	140168439738048 -> 140168439736608
	140168439738048 [label=ViewBackward0]
	140168439735456 -> 140168439738048
	140168439736560 -> 140168439736608
	140168439736560 [label=TBackward0]
	140168439361264 -> 140168439736560
	140168439290992 [label="transformer_encoder.layers.0.linear1.weight
 (2048, 128)" fillcolor=lightblue]
	140168439290992 -> 140168439361264
	140168439361264 [label=AccumulateGrad]
	140168439735888 -> 140168439735792
	140168439735888 [label=TBackward0]
	140168439360688 -> 140168439735888
	140168439291184 [label="transformer_encoder.layers.0.linear2.weight
 (128, 2048)" fillcolor=lightblue]
	140168439291184 -> 140168439360688
	140168439360688 [label=AccumulateGrad]
	140168439358096 -> 140168439735216
	140168439291568 [label="transformer_encoder.layers.0.norm2.weight
 (128)" fillcolor=lightblue]
	140168439291568 -> 140168439358096
	140168439358096 [label=AccumulateGrad]
	140168439358048 -> 140168439735216
	140168439291664 [label="transformer_encoder.layers.0.norm2.bias
 (128)" fillcolor=lightblue]
	140168439291664 -> 140168439358048
	140168439358048 [label=AccumulateGrad]
	140168439735168 -> 140168439735120
	140168439735168 [label=TransposeBackward0]
	140168439735504 -> 140168439735168
	140168439735504 [label=ViewBackward0]
	140168439737376 -> 140168439735504
	140168439737376 [label=AddmmBackward0]
	140168439360928 -> 140168439737376
	140168439292048 [label="transformer_encoder.layers.1.self_attn.out_proj.bias
 (128)" fillcolor=lightblue]
	140168439292048 -> 140168439360928
	140168439360928 [label=AccumulateGrad]
	140168439736512 -> 140168439737376
	140168439736512 [label=ViewBackward0]
	140168439736224 -> 140168439736512
	140168439736224 [label=CloneBackward0]
	140168439737568 -> 140168439736224
	140168439737568 [label=PermuteBackward0]
	140168439737760 -> 140168439737568
	140168439737760 [label=ScaledDotProductFlashAttentionForCpuBackward0]
	140168439738144 -> 140168439737760
	140168439738144 [label=ViewBackward0]
	140168439738336 -> 140168439738144
	140168439738336 [label=TransposeBackward0]
	140168439364048 -> 140168439738336
	140168439364048 [label=ViewBackward0]
	140168439364000 -> 140168439364048
	140168439364000 [label=SelectBackward0]
	140168439363952 -> 140168439364000
	140168439363952 [label=CloneBackward0]
	140168439363280 -> 140168439363952
	140168439363280 [label=SqueezeBackward1]
	140168439362752 -> 140168439363280
	140168439362752 [label=TransposeBackward0]
	140168439361504 -> 140168439362752
	140168439361504 [label=UnsqueezeBackward0]
	140168439357568 -> 140168439361504
	140168439357568 [label=ViewBackward0]
	140168439363760 -> 140168439357568
	140168439363760 [label=AddBackward0]
	140168439363712 -> 140168439363760
	140168439363712 [label=UnsafeViewBackward0]
	140168439363376 -> 140168439363712
	140168439363376 [label=MmBackward0]
	140168439351088 -> 140168439363376
	140168439351088 [label=UnsafeViewBackward0]
	140168439365584 -> 140168439351088
	140168439365584 [label=CloneBackward0]
	140168439365488 -> 140168439365584
	140168439365488 [label=TransposeBackward0]
	140168439735216 -> 140168439365488
	140168439363424 -> 140168439363376
	140168439363424 [label=TBackward0]
	140168439365392 -> 140168439363424
	140168439291760 [label="transformer_encoder.layers.1.self_attn.in_proj_weight
 (384, 128)" fillcolor=lightblue]
	140168439291760 -> 140168439365392
	140168439365392 [label=AccumulateGrad]
	140168439357040 -> 140168439363760
	140168439291856 [label="transformer_encoder.layers.1.self_attn.in_proj_bias
 (384)" fillcolor=lightblue]
	140168439291856 -> 140168439357040
	140168439357040 [label=AccumulateGrad]
	140168439738096 -> 140168439737760
	140168439738096 [label=ViewBackward0]
	140168439361696 -> 140168439738096
	140168439361696 [label=TransposeBackward0]
	140168439362800 -> 140168439361696
	140168439362800 [label=ViewBackward0]
	140168439359632 -> 140168439362800
	140168439359632 [label=SelectBackward0]
	140168439363952 -> 140168439359632
	140168439737808 -> 140168439737760
	140168439737808 [label=ViewBackward0]
	140168439362656 -> 140168439737808
	140168439362656 [label=TransposeBackward0]
	140168439357520 -> 140168439362656
	140168439357520 [label=ViewBackward0]
	140168439365536 -> 140168439357520
	140168439365536 [label=SelectBackward0]
	140168439363952 -> 140168439365536
	140168439736128 -> 140168439737376
	140168439736128 [label=TBackward0]
	140168439357328 -> 140168439736128
	140168439291952 [label="transformer_encoder.layers.1.self_attn.out_proj.weight
 (128, 128)" fillcolor=lightblue]
	140168439291952 -> 140168439357328
	140168439357328 [label=AccumulateGrad]
	140168439357760 -> 140168439734976
	140168439292528 [label="transformer_encoder.layers.1.norm1.weight
 (128)" fillcolor=lightblue]
	140168439292528 -> 140168439357760
	140168439357760 [label=AccumulateGrad]
	140168439357712 -> 140168439734976
	140168439292624 [label="transformer_encoder.layers.1.norm1.bias
 (128)" fillcolor=lightblue]
	140168439292624 -> 140168439357712
	140168439357712 [label=AccumulateGrad]
	140168439734928 -> 140168439734880
	140168439734928 [label=ViewBackward0]
	140168439357904 -> 140168439734928
	140168439357904 [label=AddmmBackward0]
	140168439364240 -> 140168439357904
	140168439292432 [label="transformer_encoder.layers.1.linear2.bias
 (128)" fillcolor=lightblue]
	140168439292432 -> 140168439364240
	140168439364240 [label=AccumulateGrad]
	140168439363328 -> 140168439357904
	140168439363328 [label=ViewBackward0]
	140168439365440 -> 140168439363328
	140168439365440 [label=ReluBackward0]
	140168439365248 -> 140168439365440
	140168439365248 [label=ViewBackward0]
	140168439365152 -> 140168439365248
	140168439365152 [label=AddmmBackward0]
	140168439365056 -> 140168439365152
	140168439292240 [label="transformer_encoder.layers.1.linear1.bias
 (2048)" fillcolor=lightblue]
	140168439292240 -> 140168439365056
	140168439365056 [label=AccumulateGrad]
	140168439365104 -> 140168439365152
	140168439365104 [label=ViewBackward0]
	140168439734976 -> 140168439365104
	140168439365344 -> 140168439365152
	140168439365344 [label=TBackward0]
	140168439364864 -> 140168439365344
	140168439292144 [label="transformer_encoder.layers.1.linear1.weight
 (2048, 128)" fillcolor=lightblue]
	140168439292144 -> 140168439364864
	140168439364864 [label=AccumulateGrad]
	140168439357232 -> 140168439357904
	140168439357232 [label=TBackward0]
	140168439365200 -> 140168439357232
	140168439292336 [label="transformer_encoder.layers.1.linear2.weight
 (128, 2048)" fillcolor=lightblue]
	140168439292336 -> 140168439365200
	140168439365200 [label=AccumulateGrad]
	140168439357424 -> 140168439734688
	140168439292720 [label="transformer_encoder.layers.1.norm2.weight
 (128)" fillcolor=lightblue]
	140168439292720 -> 140168439357424
	140168439357424 [label=AccumulateGrad]
	140168439357376 -> 140168439734688
	140168439292816 [label="transformer_encoder.layers.1.norm2.bias
 (128)" fillcolor=lightblue]
	140168439292816 -> 140168439357376
	140168439357376 [label=AccumulateGrad]
	140168439734592 -> 140168439729888
	140168439734592 [label=TBackward0]
	140168439365296 -> 140168439734592
	140168439293008 [label="pre_classifier.weight
 (128, 3072)" fillcolor=lightblue]
	140168439293008 -> 140168439365296
	140168439365296 [label=AccumulateGrad]
	140168439729552 -> 140168439729600
	140168439729552 [label=TBackward0]
	140168439364912 -> 140168439729552
	140168439293200 [label="classifier.weight
 (4, 128)" fillcolor=lightblue]
	140168439293200 -> 140168439364912
	140168439364912 [label=AccumulateGrad]
	140168439727728 -> 140168439777808
}
