digraph {
	graph [size="48.75,48.75"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140168439822096 [label="
 (10, 4)" fillcolor=darkolivegreen1]
	140168439728784 [label=LogSoftmaxBackward0]
	140168439726432 -> 140168439728784
	140168439726432 [label=AddmmBackward0]
	140168439356944 -> 140168439726432
	140168439293296 [label="classifier.bias
 (4)" fillcolor=lightblue]
	140168439293296 -> 140168439356944
	140168439356944 [label=AccumulateGrad]
	140168439729216 -> 140168439726432
	140168439729216 [label=ReluBackward0]
	140168439728112 -> 140168439729216
	140168439728112 [label=AddmmBackward0]
	140168439357184 -> 140168439728112
	140168439293104 [label="pre_classifier.bias
 (128)" fillcolor=lightblue]
	140168439293104 -> 140168439357184
	140168439357184 [label=AccumulateGrad]
	140168439729168 -> 140168439728112
	140168439729168 [label=ViewBackward0]
	140168439729504 -> 140168439729168
	140168439729504 [label=NativeLayerNormBackward0]
	140168439729696 -> 140168439729504
	140168439729696 [label=AddBackward0]
	140168439729792 -> 140168439729696
	140168439729792 [label=NativeLayerNormBackward0]
	140168439729936 -> 140168439729792
	140168439729936 [label=AddBackward0]
	140168439730032 -> 140168439729936
	140168439730032 [label=NativeLayerNormBackward0]
	140168439730176 -> 140168439730032
	140168439730176 [label=AddBackward0]
	140168439730272 -> 140168439730176
	140168439730272 [label=NativeLayerNormBackward0]
	140168439730416 -> 140168439730272
	140168439730416 [label=AddBackward0]
	140168439730512 -> 140168439730416
	140168439730512 [label=NativeLayerNormBackward0]
	140168439358816 -> 140168439730512
	140168439288592 [label="norm.weight
 (128)" fillcolor=lightblue]
	140168439288592 -> 140168439358816
	140168439358816 [label=AccumulateGrad]
	140168439358768 -> 140168439730512
	140168439288688 [label="norm.bias
 (128)" fillcolor=lightblue]
	140168439288688 -> 140168439358768
	140168439358768 [label=AccumulateGrad]
	140168439730464 -> 140168439730416
	140168439730464 [label=TransposeBackward0]
	140168439730560 -> 140168439730464
	140168439730560 [label=ViewBackward0]
	140168439730752 -> 140168439730560
	140168439730752 [label=AddmmBackward0]
	140168439359104 -> 140168439730752
	140168439290896 [label="transformer_encoder.layers.0.self_attn.out_proj.bias
 (128)" fillcolor=lightblue]
	140168439290896 -> 140168439359104
	140168439359104 [label=AccumulateGrad]
	140168439730848 -> 140168439730752
	140168439730848 [label=ViewBackward0]
	140168439730896 -> 140168439730848
	140168439730896 [label=CloneBackward0]
	140168439731088 -> 140168439730896
	140168439731088 [label=PermuteBackward0]
	140168439731184 -> 140168439731088
	140168439731184 [label=ScaledDotProductFlashAttentionForCpuBackward0]
	140168439731280 -> 140168439731184
	140168439731280 [label=ViewBackward0]
	140168439731472 -> 140168439731280
	140168439731472 [label=TransposeBackward0]
	140168439731568 -> 140168439731472
	140168439731568 [label=ViewBackward0]
	140168439731664 -> 140168439731568
	140168439731664 [label=SelectBackward0]
	140168439731760 -> 140168439731664
	140168439731760 [label=CloneBackward0]
	140168439731856 -> 140168439731760
	140168439731856 [label=SqueezeBackward1]
	140168439731952 -> 140168439731856
	140168439731952 [label=TransposeBackward0]
	140168439732048 -> 140168439731952
	140168439732048 [label=UnsqueezeBackward0]
	140168439732144 -> 140168439732048
	140168439732144 [label=ViewBackward0]
	140168439732240 -> 140168439732144
	140168439732240 [label=AddBackward0]
	140168439732336 -> 140168439732240
	140168439732336 [label=UnsafeViewBackward0]
	140168439732432 -> 140168439732336
	140168439732432 [label=MmBackward0]
	140168439732528 -> 140168439732432
	140168439732528 [label=UnsafeViewBackward0]
	140168439732672 -> 140168439732528
	140168439732672 [label=CloneBackward0]
	140168439732768 -> 140168439732672
	140168439732768 [label=TransposeBackward0]
	140168439730512 -> 140168439732768
	140168439732480 -> 140168439732432
	140168439732480 [label=TBackward0]
	140168439361216 -> 140168439732480
	140168439288880 [label="transformer_encoder.layers.0.self_attn.in_proj_weight
 (384, 128)" fillcolor=lightblue]
	140168439288880 -> 140168439361216
	140168439361216 [label=AccumulateGrad]
	140168439360592 -> 140168439732240
	140168439290512 [label="transformer_encoder.layers.0.self_attn.in_proj_bias
 (384)" fillcolor=lightblue]
	140168439290512 -> 140168439360592
	140168439360592 [label=AccumulateGrad]
	140168439731232 -> 140168439731184
	140168439731232 [label=ViewBackward0]
	140168439731616 -> 140168439731232
	140168439731616 [label=TransposeBackward0]
	140168439731808 -> 140168439731616
	140168439731808 [label=ViewBackward0]
	140168439732000 -> 140168439731808
	140168439732000 [label=SelectBackward0]
	140168439731760 -> 140168439732000
	140168439730992 -> 140168439731184
	140168439730992 [label=ViewBackward0]
	140168439731904 -> 140168439730992
	140168439731904 [label=TransposeBackward0]
	140168439732096 -> 140168439731904
	140168439732096 [label=ViewBackward0]
	140168439732288 -> 140168439732096
	140168439732288 [label=SelectBackward0]
	140168439731760 -> 140168439732288
	140168439730800 -> 140168439730752
	140168439730800 [label=TBackward0]
	140168439359440 -> 140168439730800
	140168439290608 [label="transformer_encoder.layers.0.self_attn.out_proj.weight
 (128, 128)" fillcolor=lightblue]
	140168439290608 -> 140168439359440
	140168439359440 [label=AccumulateGrad]
	140168439358432 -> 140168439730272
	140168439291376 [label="transformer_encoder.layers.0.norm1.weight
 (128)" fillcolor=lightblue]
	140168439291376 -> 140168439358432
	140168439358432 [label=AccumulateGrad]
	140168439358384 -> 140168439730272
	140168439291472 [label="transformer_encoder.layers.0.norm1.bias
 (128)" fillcolor=lightblue]
	140168439291472 -> 140168439358384
	140168439358384 [label=AccumulateGrad]
	140168439730224 -> 140168439730176
	140168439730224 [label=ViewBackward0]
	140168439730608 -> 140168439730224
	140168439730608 [label=AddmmBackward0]
	140168439359152 -> 140168439730608
	140168439291280 [label="transformer_encoder.layers.0.linear2.bias
 (128)" fillcolor=lightblue]
	140168439291280 -> 140168439359152
	140168439359152 [label=AccumulateGrad]
	140168439730656 -> 140168439730608
	140168439730656 [label=ViewBackward0]
	140168439731136 -> 140168439730656
	140168439731136 [label=ReluBackward0]
	140168439731712 -> 140168439731136
	140168439731712 [label=ViewBackward0]
	140168439731424 -> 140168439731712
	140168439731424 [label=AddmmBackward0]
	140168439360736 -> 140168439731424
	140168439291088 [label="transformer_encoder.layers.0.linear1.bias
 (2048)" fillcolor=lightblue]
	140168439291088 -> 140168439360736
	140168439360736 [label=AccumulateGrad]
	140168439732864 -> 140168439731424
	140168439732864 [label=ViewBackward0]
	140168439730272 -> 140168439732864
	140168439731376 -> 140168439731424
	140168439731376 [label=TBackward0]
	140168439361264 -> 140168439731376
	140168439290992 [label="transformer_encoder.layers.0.linear1.weight
 (2048, 128)" fillcolor=lightblue]
	140168439290992 -> 140168439361264
	140168439361264 [label=AccumulateGrad]
	140168439730704 -> 140168439730608
	140168439730704 [label=TBackward0]
	140168439360688 -> 140168439730704
	140168439291184 [label="transformer_encoder.layers.0.linear2.weight
 (128, 2048)" fillcolor=lightblue]
	140168439291184 -> 140168439360688
	140168439360688 [label=AccumulateGrad]
	140168439358096 -> 140168439730032
	140168439291568 [label="transformer_encoder.layers.0.norm2.weight
 (128)" fillcolor=lightblue]
	140168439291568 -> 140168439358096
	140168439358096 [label=AccumulateGrad]
	140168439358048 -> 140168439730032
	140168439291664 [label="transformer_encoder.layers.0.norm2.bias
 (128)" fillcolor=lightblue]
	140168439291664 -> 140168439358048
	140168439358048 [label=AccumulateGrad]
	140168439729984 -> 140168439729936
	140168439729984 [label=TransposeBackward0]
	140168439730320 -> 140168439729984
	140168439730320 [label=ViewBackward0]
	140168439732192 -> 140168439730320
	140168439732192 [label=AddmmBackward0]
	140168439360928 -> 140168439732192
	140168439292048 [label="transformer_encoder.layers.1.self_attn.out_proj.bias
 (128)" fillcolor=lightblue]
	140168439292048 -> 140168439360928
	140168439360928 [label=AccumulateGrad]
	140168439731328 -> 140168439732192
	140168439731328 [label=ViewBackward0]
	140168439731040 -> 140168439731328
	140168439731040 [label=CloneBackward0]
	140168439732384 -> 140168439731040
	140168439732384 [label=PermuteBackward0]
	140168439732576 -> 140168439732384
	140168439732576 [label=ScaledDotProductFlashAttentionForCpuBackward0]
	140168439732960 -> 140168439732576
	140168439732960 [label=ViewBackward0]
	140168439733152 -> 140168439732960
	140168439733152 [label=TransposeBackward0]
	140168439733248 -> 140168439733152
	140168439733248 [label=ViewBackward0]
	140168439733344 -> 140168439733248
	140168439733344 [label=SelectBackward0]
	140168439733440 -> 140168439733344
	140168439733440 [label=CloneBackward0]
	140168439733536 -> 140168439733440
	140168439733536 [label=SqueezeBackward1]
	140168439733632 -> 140168439733536
	140168439733632 [label=TransposeBackward0]
	140168439733728 -> 140168439733632
	140168439733728 [label=UnsqueezeBackward0]
	140168439733824 -> 140168439733728
	140168439733824 [label=ViewBackward0]
	140168439733920 -> 140168439733824
	140168439733920 [label=AddBackward0]
	140168439734016 -> 140168439733920
	140168439734016 [label=UnsafeViewBackward0]
	140168439734112 -> 140168439734016
	140168439734112 [label=MmBackward0]
	140168439734208 -> 140168439734112
	140168439734208 [label=UnsafeViewBackward0]
	140168439734352 -> 140168439734208
	140168439734352 [label=CloneBackward0]
	140168439734448 -> 140168439734352
	140168439734448 [label=TransposeBackward0]
	140168439730032 -> 140168439734448
	140168439734160 -> 140168439734112
	140168439734160 [label=TBackward0]
	140168439363280 -> 140168439734160
	140168439291760 [label="transformer_encoder.layers.1.self_attn.in_proj_weight
 (384, 128)" fillcolor=lightblue]
	140168439291760 -> 140168439363280
	140168439363280 [label=AccumulateGrad]
	140168439362656 -> 140168439733920
	140168439291856 [label="transformer_encoder.layers.1.self_attn.in_proj_bias
 (384)" fillcolor=lightblue]
	140168439291856 -> 140168439362656
	140168439362656 [label=AccumulateGrad]
	140168439732912 -> 140168439732576
	140168439732912 [label=ViewBackward0]
	140168439733296 -> 140168439732912
	140168439733296 [label=TransposeBackward0]
	140168439733488 -> 140168439733296
	140168439733488 [label=ViewBackward0]
	140168439733680 -> 140168439733488
	140168439733680 [label=SelectBackward0]
	140168439733440 -> 140168439733680
	140168439732624 -> 140168439732576
	140168439732624 [label=ViewBackward0]
	140168439733584 -> 140168439732624
	140168439733584 [label=TransposeBackward0]
	140168439733776 -> 140168439733584
	140168439733776 [label=ViewBackward0]
	140168439733968 -> 140168439733776
	140168439733968 [label=SelectBackward0]
	140168439733440 -> 140168439733968
	140168439730944 -> 140168439732192
	140168439730944 [label=TBackward0]
	140168439361504 -> 140168439730944
	140168439291952 [label="transformer_encoder.layers.1.self_attn.out_proj.weight
 (128, 128)" fillcolor=lightblue]
	140168439291952 -> 140168439361504
	140168439361504 [label=AccumulateGrad]
	140168439357760 -> 140168439729792
	140168439292528 [label="transformer_encoder.layers.1.norm1.weight
 (128)" fillcolor=lightblue]
	140168439292528 -> 140168439357760
	140168439357760 [label=AccumulateGrad]
	140168439357712 -> 140168439729792
	140168439292624 [label="transformer_encoder.layers.1.norm1.bias
 (128)" fillcolor=lightblue]
	140168439292624 -> 140168439357712
	140168439357712 [label=AccumulateGrad]
	140168439729744 -> 140168439729696
	140168439729744 [label=ViewBackward0]
	140168439730080 -> 140168439729744
	140168439730080 [label=AddmmBackward0]
	140168439359632 -> 140168439730080
	140168439292432 [label="transformer_encoder.layers.1.linear2.bias
 (128)" fillcolor=lightblue]
	140168439292432 -> 140168439359632
	140168439359632 [label=AccumulateGrad]
	140168439730128 -> 140168439730080
	140168439730128 [label=ViewBackward0]
	140168439732720 -> 140168439730128
	140168439732720 [label=ReluBackward0]
	140168439733392 -> 140168439732720
	140168439733392 [label=ViewBackward0]
	140168439733104 -> 140168439733392
	140168439733104 [label=AddmmBackward0]
	140168439362800 -> 140168439733104
	140168439292240 [label="transformer_encoder.layers.1.linear1.bias
 (2048)" fillcolor=lightblue]
	140168439292240 -> 140168439362800
	140168439362800 [label=AccumulateGrad]
	140168439734544 -> 140168439733104
	140168439734544 [label=ViewBackward0]
	140168439729792 -> 140168439734544
	140168439733056 -> 140168439733104
	140168439733056 [label=TBackward0]
	140168439363328 -> 140168439733056
	140168439292144 [label="transformer_encoder.layers.1.linear1.weight
 (2048, 128)" fillcolor=lightblue]
	140168439292144 -> 140168439363328
	140168439363328 [label=AccumulateGrad]
	140168439730368 -> 140168439730080
	140168439730368 [label=TBackward0]
	140168439362752 -> 140168439730368
	140168439292336 [label="transformer_encoder.layers.1.linear2.weight
 (128, 2048)" fillcolor=lightblue]
	140168439292336 -> 140168439362752
	140168439362752 [label=AccumulateGrad]
	140168439357424 -> 140168439729504
	140168439292720 [label="transformer_encoder.layers.1.norm2.weight
 (128)" fillcolor=lightblue]
	140168439292720 -> 140168439357424
	140168439357424 [label=AccumulateGrad]
	140168439357376 -> 140168439729504
	140168439292816 [label="transformer_encoder.layers.1.norm2.bias
 (128)" fillcolor=lightblue]
	140168439292816 -> 140168439357376
	140168439357376 [label=AccumulateGrad]
	140168439728976 -> 140168439728112
	140168439728976 [label=TBackward0]
	140168439357568 -> 140168439728976
	140168439293008 [label="pre_classifier.weight
 (128, 3072)" fillcolor=lightblue]
	140168439293008 -> 140168439357568
	140168439357568 [label=AccumulateGrad]
	140168439729408 -> 140168439726432
	140168439729408 [label=TBackward0]
	140168439357520 -> 140168439729408
	140168439293200 [label="classifier.weight
 (4, 128)" fillcolor=lightblue]
	140168439293200 -> 140168439357520
	140168439357520 [label=AccumulateGrad]
	140168439728784 -> 140168439822096
}
