digraph {
	graph [size="48.75,48.75"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140168439622896 [label="
 (5, 4)" fillcolor=darkolivegreen1]
	140168439363520 [label=LogSoftmaxBackward0]
	140168439363616 -> 140168439363520
	140168439363616 [label=AddmmBackward0]
	140168439356944 -> 140168439363616
	140168439293296 [label="classifier.bias
 (4)" fillcolor=lightblue]
	140168439293296 -> 140168439356944
	140168439356944 [label=AccumulateGrad]
	140168439363568 -> 140168439363616
	140168439363568 [label=ReluBackward0]
	140168439363664 -> 140168439363568
	140168439363664 [label=AddmmBackward0]
	140168439357184 -> 140168439363664
	140168439293104 [label="pre_classifier.bias
 (128)" fillcolor=lightblue]
	140168439293104 -> 140168439357184
	140168439357184 [label=AccumulateGrad]
	140168439363856 -> 140168439363664
	140168439363856 [label=ViewBackward0]
	140168439363904 -> 140168439363856
	140168439363904 [label=NativeLayerNormBackward0]
	140168439364096 -> 140168439363904
	140168439364096 [label=AddBackward0]
	140168439364192 -> 140168439364096
	140168439364192 [label=NativeLayerNormBackward0]
	140168439364336 -> 140168439364192
	140168439364336 [label=AddBackward0]
	140168439364432 -> 140168439364336
	140168439364432 [label=NativeLayerNormBackward0]
	140168439364576 -> 140168439364432
	140168439364576 [label=AddBackward0]
	140168439364672 -> 140168439364576
	140168439364672 [label=NativeLayerNormBackward0]
	140168439364816 -> 140168439364672
	140168439364816 [label=AddBackward0]
	140168439364912 -> 140168439364816
	140168439364912 [label=NativeLayerNormBackward0]
	140168439358816 -> 140168439364912
	140168439288592 [label="norm.weight
 (128)" fillcolor=lightblue]
	140168439288592 -> 140168439358816
	140168439358816 [label=AccumulateGrad]
	140168439358768 -> 140168439364912
	140168439288688 [label="norm.bias
 (128)" fillcolor=lightblue]
	140168439288688 -> 140168439358768
	140168439358768 [label=AccumulateGrad]
	140168439364864 -> 140168439364816
	140168439364864 [label=TransposeBackward0]
	140168439364960 -> 140168439364864
	140168439364960 [label=ViewBackward0]
	140168439365152 -> 140168439364960
	140168439365152 [label=AddmmBackward0]
	140168439359104 -> 140168439365152
	140168439290896 [label="transformer_encoder.layers.0.self_attn.out_proj.bias
 (128)" fillcolor=lightblue]
	140168439290896 -> 140168439359104
	140168439359104 [label=AccumulateGrad]
	140168439365248 -> 140168439365152
	140168439365248 [label=ViewBackward0]
	140168439365296 -> 140168439365248
	140168439365296 [label=CloneBackward0]
	140168439365488 -> 140168439365296
	140168439365488 [label=PermuteBackward0]
	140168439365584 -> 140168439365488
	140168439365584 [label=ScaledDotProductFlashAttentionForCpuBackward0]
	140168439365392 -> 140168439365584
	140168439365392 [label=ViewBackward0]
	140168439726384 -> 140168439365392
	140168439726384 [label=TransposeBackward0]
	140168439726480 -> 140168439726384
	140168439726480 [label=ViewBackward0]
	140168439726576 -> 140168439726480
	140168439726576 [label=SelectBackward0]
	140168439726672 -> 140168439726576
	140168439726672 [label=CloneBackward0]
	140168439726768 -> 140168439726672
	140168439726768 [label=SqueezeBackward1]
	140168439726864 -> 140168439726768
	140168439726864 [label=TransposeBackward0]
	140168439726960 -> 140168439726864
	140168439726960 [label=UnsqueezeBackward0]
	140168439727056 -> 140168439726960
	140168439727056 [label=ViewBackward0]
	140168439727152 -> 140168439727056
	140168439727152 [label=AddBackward0]
	140168439727248 -> 140168439727152
	140168439727248 [label=UnsafeViewBackward0]
	140168439727344 -> 140168439727248
	140168439727344 [label=MmBackward0]
	140168439727440 -> 140168439727344
	140168439727440 [label=UnsafeViewBackward0]
	140168439727584 -> 140168439727440
	140168439727584 [label=CloneBackward0]
	140168439727680 -> 140168439727584
	140168439727680 [label=TransposeBackward0]
	140168439364912 -> 140168439727680
	140168439727392 -> 140168439727344
	140168439727392 [label=TBackward0]
	140168439361216 -> 140168439727392
	140168439288880 [label="transformer_encoder.layers.0.self_attn.in_proj_weight
 (384, 128)" fillcolor=lightblue]
	140168439288880 -> 140168439361216
	140168439361216 [label=AccumulateGrad]
	140168439360592 -> 140168439727152
	140168439290512 [label="transformer_encoder.layers.0.self_attn.in_proj_bias
 (384)" fillcolor=lightblue]
	140168439290512 -> 140168439360592
	140168439360592 [label=AccumulateGrad]
	140168439726192 -> 140168439365584
	140168439726192 [label=ViewBackward0]
	140168439726528 -> 140168439726192
	140168439726528 [label=TransposeBackward0]
	140168439726720 -> 140168439726528
	140168439726720 [label=ViewBackward0]
	140168439726912 -> 140168439726720
	140168439726912 [label=SelectBackward0]
	140168439726672 -> 140168439726912
	140168439726144 -> 140168439365584
	140168439726144 [label=ViewBackward0]
	140168439726816 -> 140168439726144
	140168439726816 [label=TransposeBackward0]
	140168439727008 -> 140168439726816
	140168439727008 [label=ViewBackward0]
	140168439727200 -> 140168439727008
	140168439727200 [label=SelectBackward0]
	140168439726672 -> 140168439727200
	140168439365200 -> 140168439365152
	140168439365200 [label=TBackward0]
	140168439359440 -> 140168439365200
	140168439290608 [label="transformer_encoder.layers.0.self_attn.out_proj.weight
 (128, 128)" fillcolor=lightblue]
	140168439290608 -> 140168439359440
	140168439359440 [label=AccumulateGrad]
	140168439358432 -> 140168439364672
	140168439291376 [label="transformer_encoder.layers.0.norm1.weight
 (128)" fillcolor=lightblue]
	140168439291376 -> 140168439358432
	140168439358432 [label=AccumulateGrad]
	140168439358384 -> 140168439364672
	140168439291472 [label="transformer_encoder.layers.0.norm1.bias
 (128)" fillcolor=lightblue]
	140168439291472 -> 140168439358384
	140168439358384 [label=AccumulateGrad]
	140168439364624 -> 140168439364576
	140168439364624 [label=ViewBackward0]
	140168439365008 -> 140168439364624
	140168439365008 [label=AddmmBackward0]
	140168439359152 -> 140168439365008
	140168439291280 [label="transformer_encoder.layers.0.linear2.bias
 (128)" fillcolor=lightblue]
	140168439291280 -> 140168439359152
	140168439359152 [label=AccumulateGrad]
	140168439365056 -> 140168439365008
	140168439365056 [label=ViewBackward0]
	140168439365536 -> 140168439365056
	140168439365536 [label=ReluBackward0]
	140168439365440 -> 140168439365536
	140168439365440 [label=ViewBackward0]
	140168439726336 -> 140168439365440
	140168439726336 [label=AddmmBackward0]
	140168439360736 -> 140168439726336
	140168439291088 [label="transformer_encoder.layers.0.linear1.bias
 (2048)" fillcolor=lightblue]
	140168439291088 -> 140168439360736
	140168439360736 [label=AccumulateGrad]
	140168439727776 -> 140168439726336
	140168439727776 [label=ViewBackward0]
	140168439364672 -> 140168439727776
	140168439726288 -> 140168439726336
	140168439726288 [label=TBackward0]
	140168439361264 -> 140168439726288
	140168439290992 [label="transformer_encoder.layers.0.linear1.weight
 (2048, 128)" fillcolor=lightblue]
	140168439290992 -> 140168439361264
	140168439361264 [label=AccumulateGrad]
	140168439365104 -> 140168439365008
	140168439365104 [label=TBackward0]
	140168439360688 -> 140168439365104
	140168439291184 [label="transformer_encoder.layers.0.linear2.weight
 (128, 2048)" fillcolor=lightblue]
	140168439291184 -> 140168439360688
	140168439360688 [label=AccumulateGrad]
	140168439358096 -> 140168439364432
	140168439291568 [label="transformer_encoder.layers.0.norm2.weight
 (128)" fillcolor=lightblue]
	140168439291568 -> 140168439358096
	140168439358096 [label=AccumulateGrad]
	140168439358048 -> 140168439364432
	140168439291664 [label="transformer_encoder.layers.0.norm2.bias
 (128)" fillcolor=lightblue]
	140168439291664 -> 140168439358048
	140168439358048 [label=AccumulateGrad]
	140168439364384 -> 140168439364336
	140168439364384 [label=TransposeBackward0]
	140168439364720 -> 140168439364384
	140168439364720 [label=ViewBackward0]
	140168439365344 -> 140168439364720
	140168439365344 [label=AddmmBackward0]
	140168439360928 -> 140168439365344
	140168439292048 [label="transformer_encoder.layers.1.self_attn.out_proj.bias
 (128)" fillcolor=lightblue]
	140168439292048 -> 140168439360928
	140168439360928 [label=AccumulateGrad]
	140168439364528 -> 140168439365344
	140168439364528 [label=ViewBackward0]
	140168439727104 -> 140168439364528
	140168439727104 [label=CloneBackward0]
	140168439727296 -> 140168439727104
	140168439727296 [label=PermuteBackward0]
	140168439727488 -> 140168439727296
	140168439727488 [label=ScaledDotProductFlashAttentionForCpuBackward0]
	140168439727872 -> 140168439727488
	140168439727872 [label=ViewBackward0]
	140168439728064 -> 140168439727872
	140168439728064 [label=TransposeBackward0]
	140168439728160 -> 140168439728064
	140168439728160 [label=ViewBackward0]
	140168439728256 -> 140168439728160
	140168439728256 [label=SelectBackward0]
	140168439728352 -> 140168439728256
	140168439728352 [label=CloneBackward0]
	140168439728448 -> 140168439728352
	140168439728448 [label=SqueezeBackward1]
	140168439728544 -> 140168439728448
	140168439728544 [label=TransposeBackward0]
	140168439728640 -> 140168439728544
	140168439728640 [label=UnsqueezeBackward0]
	140168439728736 -> 140168439728640
	140168439728736 [label=ViewBackward0]
	140168439728832 -> 140168439728736
	140168439728832 [label=AddBackward0]
	140168439728928 -> 140168439728832
	140168439728928 [label=UnsafeViewBackward0]
	140168439729024 -> 140168439728928
	140168439729024 [label=MmBackward0]
	140168439729120 -> 140168439729024
	140168439729120 [label=UnsafeViewBackward0]
	140168439729264 -> 140168439729120
	140168439729264 [label=CloneBackward0]
	140168439729360 -> 140168439729264
	140168439729360 [label=TransposeBackward0]
	140168439364432 -> 140168439729360
	140168439729072 -> 140168439729024
	140168439729072 [label=TBackward0]
	140168439363280 -> 140168439729072
	140168439291760 [label="transformer_encoder.layers.1.self_attn.in_proj_weight
 (384, 128)" fillcolor=lightblue]
	140168439291760 -> 140168439363280
	140168439363280 [label=AccumulateGrad]
	140168439362656 -> 140168439728832
	140168439291856 [label="transformer_encoder.layers.1.self_attn.in_proj_bias
 (384)" fillcolor=lightblue]
	140168439291856 -> 140168439362656
	140168439362656 [label=AccumulateGrad]
	140168439727824 -> 140168439727488
	140168439727824 [label=ViewBackward0]
	140168439728208 -> 140168439727824
	140168439728208 [label=TransposeBackward0]
	140168439728400 -> 140168439728208
	140168439728400 [label=ViewBackward0]
	140168439728592 -> 140168439728400
	140168439728592 [label=SelectBackward0]
	140168439728352 -> 140168439728592
	140168439727536 -> 140168439727488
	140168439727536 [label=ViewBackward0]
	140168439728496 -> 140168439727536
	140168439728496 [label=TransposeBackward0]
	140168439728688 -> 140168439728496
	140168439728688 [label=ViewBackward0]
	140168439728880 -> 140168439728688
	140168439728880 [label=SelectBackward0]
	140168439728352 -> 140168439728880
	140168439726624 -> 140168439365344
	140168439726624 [label=TBackward0]
	140168439361504 -> 140168439726624
	140168439291952 [label="transformer_encoder.layers.1.self_attn.out_proj.weight
 (128, 128)" fillcolor=lightblue]
	140168439291952 -> 140168439361504
	140168439361504 [label=AccumulateGrad]
	140168439357760 -> 140168439364192
	140168439292528 [label="transformer_encoder.layers.1.norm1.weight
 (128)" fillcolor=lightblue]
	140168439292528 -> 140168439357760
	140168439357760 [label=AccumulateGrad]
	140168439357712 -> 140168439364192
	140168439292624 [label="transformer_encoder.layers.1.norm1.bias
 (128)" fillcolor=lightblue]
	140168439292624 -> 140168439357712
	140168439357712 [label=AccumulateGrad]
	140168439364144 -> 140168439364096
	140168439364144 [label=ViewBackward0]
	140168439364480 -> 140168439364144
	140168439364480 [label=AddmmBackward0]
	140168439359632 -> 140168439364480
	140168439292432 [label="transformer_encoder.layers.1.linear2.bias
 (128)" fillcolor=lightblue]
	140168439292432 -> 140168439359632
	140168439359632 [label=AccumulateGrad]
	140168439364768 -> 140168439364480
	140168439364768 [label=ViewBackward0]
	140168439727632 -> 140168439364768
	140168439727632 [label=ReluBackward0]
	140168439728304 -> 140168439727632
	140168439728304 [label=ViewBackward0]
	140168439728016 -> 140168439728304
	140168439728016 [label=AddmmBackward0]
	140168439362800 -> 140168439728016
	140168439292240 [label="transformer_encoder.layers.1.linear1.bias
 (2048)" fillcolor=lightblue]
	140168439292240 -> 140168439362800
	140168439362800 [label=AccumulateGrad]
	140168439729456 -> 140168439728016
	140168439729456 [label=ViewBackward0]
	140168439364192 -> 140168439729456
	140168439727968 -> 140168439728016
	140168439727968 [label=TBackward0]
	140168439363328 -> 140168439727968
	140168439292144 [label="transformer_encoder.layers.1.linear1.weight
 (2048, 128)" fillcolor=lightblue]
	140168439292144 -> 140168439363328
	140168439363328 [label=AccumulateGrad]
	140168439364288 -> 140168439364480
	140168439364288 [label=TBackward0]
	140168439362752 -> 140168439364288
	140168439292336 [label="transformer_encoder.layers.1.linear2.weight
 (128, 2048)" fillcolor=lightblue]
	140168439292336 -> 140168439362752
	140168439362752 [label=AccumulateGrad]
	140168439357424 -> 140168439363904
	140168439292720 [label="transformer_encoder.layers.1.norm2.weight
 (128)" fillcolor=lightblue]
	140168439292720 -> 140168439357424
	140168439357424 [label=AccumulateGrad]
	140168439357376 -> 140168439363904
	140168439292816 [label="transformer_encoder.layers.1.norm2.bias
 (128)" fillcolor=lightblue]
	140168439292816 -> 140168439357376
	140168439357376 [label=AccumulateGrad]
	140168439363808 -> 140168439363664
	140168439363808 [label=TBackward0]
	140168439357568 -> 140168439363808
	140168439293008 [label="pre_classifier.weight
 (128, 3072)" fillcolor=lightblue]
	140168439293008 -> 140168439357568
	140168439357568 [label=AccumulateGrad]
	140168439363040 -> 140168439363616
	140168439363040 [label=TBackward0]
	140168439357520 -> 140168439363040
	140168439293200 [label="classifier.weight
 (4, 128)" fillcolor=lightblue]
	140168439293200 -> 140168439357520
	140168439357520 [label=AccumulateGrad]
	140168439363520 -> 140168439622896
}
