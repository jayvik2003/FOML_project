digraph {
	graph [size="46.949999999999996,46.949999999999996"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140602466744496 [label="
 (11, 4)" fillcolor=darkolivegreen1]
	140602466749168 [label=LogSoftmaxBackward0]
	140602466748736 -> 140602466749168
	140602466748736 [label=AddmmBackward0]
	140602466748928 -> 140602466748736
	140602467527072 [label="classifier.bias
 (4)" fillcolor=lightblue]
	140602467527072 -> 140602466748928
	140602466748928 [label=AccumulateGrad]
	140602466748784 -> 140602466748736
	140602466748784 [label=ReluBackward0]
	140602466750368 -> 140602466748784
	140602466750368 [label=AddmmBackward0]
	140602466748496 -> 140602466750368
	140602467526912 [label="pre_classifier.bias
 (128)" fillcolor=lightblue]
	140602467526912 -> 140602466748496
	140602466748496 [label=AccumulateGrad]
	140602466748448 -> 140602466750368
	140602466748448 [label=ReshapeAliasBackward0]
	140602466748304 -> 140602466748448
	140602466748304 [label=NativeLayerNormBackward0]
	140602466748112 -> 140602466748304
	140602466748112 [label=AddBackward0]
	140602466747872 -> 140602466748112
	140602466747872 [label=NativeLayerNormBackward0]
	140602466747488 -> 140602466747872
	140602466747488 [label=AddBackward0]
	140602466747296 -> 140602466747488
	140602466747296 [label=NativeLayerNormBackward0]
	140602466747248 -> 140602466747296
	140602466747248 [label=AddBackward0]
	140602466746960 -> 140602466747248
	140602466746960 [label=NativeLayerNormBackward0]
	140602466746672 -> 140602466746960
	140602466746672 [label=AddBackward0]
	140602466746432 -> 140602466746672
	140602466746432 [label=NativeLayerNormBackward0]
	140602466746480 -> 140602466746432
	140604774931968 [label="norm.weight
 (128)" fillcolor=lightblue]
	140604774931968 -> 140602466746480
	140602466746480 [label=AccumulateGrad]
	140602467245984 -> 140602466746432
	140602534215408 [label="norm.bias
 (128)" fillcolor=lightblue]
	140602534215408 -> 140602467245984
	140602467245984 [label=AccumulateGrad]
	140602466746576 -> 140602466746672
	140602466746576 [label=TransposeBackward0]
	140602467245840 -> 140602466746576
	140602467245840 [label=ViewBackward0]
	140602467245648 -> 140602467245840
	140602467245648 [label=AddmmBackward0]
	140602467245504 -> 140602467245648
	140602467528112 [label="transformer_encoder.layers.0.self_attn.out_proj.bias
 (128)" fillcolor=lightblue]
	140602467528112 -> 140602467245504
	140602467245504 [label=AccumulateGrad]
	140602467245552 -> 140602467245648
	140602467245552 [label=ViewBackward0]
	140602467245456 -> 140602467245552
	140602467245456 [label=CloneBackward0]
	140602467245216 -> 140602467245456
	140602467245216 [label=TransposeBackward0]
	140602467245072 -> 140602467245216
	140602467245072 [label=BmmBackward0]
	140602467244880 -> 140602467245072
	140602467244880 [label=SoftmaxBackward0]
	140602467244544 -> 140602467244880
	140602467244544 [label=BmmBackward0]
	140602467244352 -> 140602467244544
	140602467244352 [label=DivBackward0]
	140602467244256 -> 140602467244352
	140602467244256 [label=TransposeBackward0]
	140602467244112 -> 140602467244256
	140602467244112 [label=ViewBackward0]
	140602467243920 -> 140602467244112
	140602467243920 [label=CloneBackward0]
	140602467243776 -> 140602467243920
	140602467243776 [label=SplitBackward0]
	140602467243632 -> 140602467243776
	140602467243632 [label=AddBackward0]
	140602467243440 -> 140602467243632
	140602467243440 [label=UnsafeViewBackward0]
	140602467243104 -> 140602467243440
	140602467243104 [label=MmBackward0]
	140602467242912 -> 140602467243104
	140602467242912 [label=UnsafeViewBackward0]
	140602467242816 -> 140602467242912
	140602467242816 [label=CloneBackward0]
	140602467242768 -> 140602467242816
	140602467242768 [label=TransposeBackward0]
	140602466746432 -> 140602467242768
	140602467243152 -> 140602467243104
	140602467243152 [label=TBackward0]
	140602467242672 -> 140602467243152
	140602467527712 [label="transformer_encoder.layers.0.self_attn.in_proj_weight
 (384, 128)" fillcolor=lightblue]
	140602467527712 -> 140602467242672
	140602467242672 [label=AccumulateGrad]
	140602467243392 -> 140602467243632
	140602467527472 [label="transformer_encoder.layers.0.self_attn.in_proj_bias
 (384)" fillcolor=lightblue]
	140602467527472 -> 140602467243392
	140602467243392 [label=AccumulateGrad]
	140602467244592 -> 140602467244544
	140602467244592 [label=TransposeBackward0]
	140602467243872 -> 140602467244592
	140602467243872 [label=TransposeBackward0]
	140602467243584 -> 140602467243872
	140602467243584 [label=ViewBackward0]
	140602467242720 -> 140602467243584
	140602467242720 [label=CloneBackward0]
	140602467243776 -> 140602467242720
	140602467244832 -> 140602467245072
	140602467244832 [label=TransposeBackward0]
	140602467244064 -> 140602467244832
	140602467244064 [label=ViewBackward0]
	140602467244400 -> 140602467244064
	140602467244400 [label=CloneBackward0]
	140602467243776 -> 140602467244400
	140602467246032 -> 140602467245648
	140602467246032 [label=TBackward0]
	140602467245024 -> 140602467246032
	140602467528352 [label="transformer_encoder.layers.0.self_attn.out_proj.weight
 (128, 128)" fillcolor=lightblue]
	140602467528352 -> 140602467245024
	140602467245024 [label=AccumulateGrad]
	140602466746768 -> 140602466746960
	140602467528192 [label="transformer_encoder.layers.0.norm1.weight
 (128)" fillcolor=lightblue]
	140602467528192 -> 140602466746768
	140602466746768 [label=AccumulateGrad]
	140602466746720 -> 140602466746960
	140602467528432 [label="transformer_encoder.layers.0.norm1.bias
 (128)" fillcolor=lightblue]
	140602467528432 -> 140602466746720
	140602466746720 [label=AccumulateGrad]
	140602466746912 -> 140602466747248
	140602466746912 [label=ViewBackward0]
	140602466746528 -> 140602466746912
	140602466746528 [label=AddmmBackward0]
	140602467245408 -> 140602466746528
	140602467528512 [label="transformer_encoder.layers.0.linear2.bias
 (128)" fillcolor=lightblue]
	140602467528512 -> 140602467245408
	140602467245408 [label=AccumulateGrad]
	140602467245600 -> 140602466746528
	140602467245600 [label=ViewBackward0]
	140602467244784 -> 140602467245600
	140602467244784 [label=ReluBackward0]
	140602467243344 -> 140602467244784
	140602467243344 [label=ViewBackward0]
	140602467244736 -> 140602467243344
	140602467244736 [label=AddmmBackward0]
	140602467242960 -> 140602467244736
	140602467527872 [label="transformer_encoder.layers.0.linear1.bias
 (2048)" fillcolor=lightblue]
	140602467527872 -> 140602467242960
	140602467242960 [label=AccumulateGrad]
	140602467244304 -> 140602467244736
	140602467244304 [label=ViewBackward0]
	140602466746960 -> 140602467244304
	140602467245312 -> 140602467244736
	140602467245312 [label=TBackward0]
	140602467242528 -> 140602467245312
	140602467527952 [label="transformer_encoder.layers.0.linear1.weight
 (2048, 128)" fillcolor=lightblue]
	140602467527952 -> 140602467242528
	140602467242528 [label=AccumulateGrad]
	140602467245792 -> 140602466746528
	140602467245792 [label=TBackward0]
	140602467243296 -> 140602467245792
	140602467528032 [label="transformer_encoder.layers.0.linear2.weight
 (128, 2048)" fillcolor=lightblue]
	140602467528032 -> 140602467243296
	140602467243296 [label=AccumulateGrad]
	140602466747200 -> 140602466747296
	140602467528592 [label="transformer_encoder.layers.0.norm2.weight
 (128)" fillcolor=lightblue]
	140602467528592 -> 140602466747200
	140602466747200 [label=AccumulateGrad]
	140602466747344 -> 140602466747296
	140602467131456 [label="transformer_encoder.layers.0.norm2.bias
 (128)" fillcolor=lightblue]
	140602467131456 -> 140602466747344
	140602466747344 [label=AccumulateGrad]
	140602466747392 -> 140602466747488
	140602466747392 [label=TransposeBackward0]
	140602466746624 -> 140602466747392
	140602466746624 [label=ViewBackward0]
	140602466747152 -> 140602466746624
	140602466747152 [label=AddmmBackward0]
	140602467242624 -> 140602466747152
	140602467131936 [label="transformer_encoder.layers.1.self_attn.out_proj.bias
 (128)" fillcolor=lightblue]
	140602467131936 -> 140602467242624
	140602467242624 [label=AccumulateGrad]
	140602467242576 -> 140602466747152
	140602467242576 [label=ViewBackward0]
	140602467242384 -> 140602467242576
	140602467242384 [label=CloneBackward0]
	140602467242192 -> 140602467242384
	140602467242192 [label=TransposeBackward0]
	140602467242048 -> 140602467242192
	140602467242048 [label=BmmBackward0]
	140602467242864 -> 140602467242048
	140602467242864 [label=SoftmaxBackward0]
	140602467213072 -> 140602467242864
	140602467213072 [label=BmmBackward0]
	140602467212832 -> 140602467213072
	140602467212832 [label=DivBackward0]
	140602467212688 -> 140602467212832
	140602467212688 [label=TransposeBackward0]
	140602467212544 -> 140602467212688
	140602467212544 [label=ViewBackward0]
	140602467212496 -> 140602467212544
	140602467212496 [label=CloneBackward0]
	140602467212400 -> 140602467212496
	140602467212400 [label=SplitBackward0]
	140602467212256 -> 140602467212400
	140602467212256 [label=AddBackward0]
	140602467212112 -> 140602467212256
	140602467212112 [label=UnsafeViewBackward0]
	140602467211824 -> 140602467212112
	140602467211824 [label=MmBackward0]
	140602467211680 -> 140602467211824
	140602467211680 [label=UnsafeViewBackward0]
	140602467211632 -> 140602467211680
	140602467211632 [label=CloneBackward0]
	140602467211488 -> 140602467211632
	140602467211488 [label=TransposeBackward0]
	140602466747296 -> 140602467211488
	140602467211776 -> 140602467211824
	140602467211776 [label=TBackward0]
	140602467211392 -> 140602467211776
	140602467527392 [label="transformer_encoder.layers.1.self_attn.in_proj_weight
 (384, 128)" fillcolor=lightblue]
	140602467527392 -> 140602467211392
	140602467211392 [label=AccumulateGrad]
	140602467212064 -> 140602467212256
	140602467131536 [label="transformer_encoder.layers.1.self_attn.in_proj_bias
 (384)" fillcolor=lightblue]
	140602467131536 -> 140602467212064
	140602467212064 [label=AccumulateGrad]
	140602467213024 -> 140602467213072
	140602467213024 [label=TransposeBackward0]
	140602467212448 -> 140602467213024
	140602467212448 [label=TransposeBackward0]
	140602467212304 -> 140602467212448
	140602467212304 [label=ViewBackward0]
	140602467211536 -> 140602467212304
	140602467211536 [label=CloneBackward0]
	140602467212400 -> 140602467211536
	140602467213264 -> 140602467242048
	140602467213264 [label=TransposeBackward0]
	140602467212592 -> 140602467213264
	140602467212592 [label=ViewBackward0]
	140602467212880 -> 140602467212592
	140602467212880 [label=CloneBackward0]
	140602467212400 -> 140602467212880
	140602467245264 -> 140602466747152
	140602467245264 [label=TBackward0]
	140602467242096 -> 140602467245264
	140602467132096 [label="transformer_encoder.layers.1.self_attn.out_proj.weight
 (128, 128)" fillcolor=lightblue]
	140602467132096 -> 140602467242096
	140602467242096 [label=AccumulateGrad]
	140602466747728 -> 140602466747872
	140602467132016 [label="transformer_encoder.layers.1.norm1.weight
 (128)" fillcolor=lightblue]
	140602467132016 -> 140602466747728
	140602466747728 [label=AccumulateGrad]
	140602466747680 -> 140602466747872
	140602467131776 [label="transformer_encoder.layers.1.norm1.bias
 (128)" fillcolor=lightblue]
	140602467131776 -> 140602466747680
	140602466747680 [label=AccumulateGrad]
	140602466747920 -> 140602466748112
	140602466747920 [label=ViewBackward0]
	140602466747104 -> 140602466747920
	140602466747104 [label=AddmmBackward0]
	140602466747536 -> 140602466747104
	140602467132256 [label="transformer_encoder.layers.1.linear2.bias
 (128)" fillcolor=lightblue]
	140602467132256 -> 140602466747536
	140602466747536 [label=AccumulateGrad]
	140602467245360 -> 140602466747104
	140602467245360 [label=ViewBackward0]
	140602467242336 -> 140602467245360
	140602467242336 [label=ReluBackward0]
	140602467211872 -> 140602467242336
	140602467211872 [label=ViewBackward0]
	140602467213168 -> 140602467211872
	140602467213168 [label=AddmmBackward0]
	140602467211728 -> 140602467213168
	140602467131616 [label="transformer_encoder.layers.1.linear1.bias
 (2048)" fillcolor=lightblue]
	140602467131616 -> 140602467211728
	140602467211728 [label=AccumulateGrad]
	140602467212640 -> 140602467213168
	140602467212640 [label=ViewBackward0]
	140602466747872 -> 140602467212640
	140602467213216 -> 140602467213168
	140602467213216 [label=TBackward0]
	140602467211296 -> 140602467213216
	140602467131696 [label="transformer_encoder.layers.1.linear1.weight
 (2048, 128)" fillcolor=lightblue]
	140602467131696 -> 140602467211296
	140602467211296 [label=AccumulateGrad]
	140602467243824 -> 140602466747104
	140602467243824 [label=TBackward0]
	140602467211920 -> 140602467243824
	140602467131856 [label="transformer_encoder.layers.1.linear2.weight
 (128, 2048)" fillcolor=lightblue]
	140602467131856 -> 140602467211920
	140602467211920 [label=AccumulateGrad]
	140602466748064 -> 140602466748304
	140602467132336 [label="transformer_encoder.layers.1.norm2.weight
 (128)" fillcolor=lightblue]
	140602467132336 -> 140602466748064
	140602466748064 [label=AccumulateGrad]
	140602466748160 -> 140602466748304
	140602467132176 [label="transformer_encoder.layers.1.norm2.bias
 (128)" fillcolor=lightblue]
	140602467132176 -> 140602466748160
	140602466748160 [label=AccumulateGrad]
	140602466748640 -> 140602466750368
	140602466748640 [label=TBackward0]
	140602466748016 -> 140602466748640
	140602467525872 [label="pre_classifier.weight
 (128, 3072)" fillcolor=lightblue]
	140602467525872 -> 140602466748016
	140602466748016 [label=AccumulateGrad]
	140602466748976 -> 140602466748736
	140602466748976 [label=TBackward0]
	140602467242144 -> 140602466748976
	140602467526992 [label="classifier.weight
 (4, 128)" fillcolor=lightblue]
	140602467526992 -> 140602467242144
	140602467242144 [label=AccumulateGrad]
	140602466749168 -> 140602466744496
}
